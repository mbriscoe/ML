{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b5646fc",
   "metadata": {},
   "source": [
    "# Brief Machine Learning Tutorial\n",
    "\n",
    "Welcome to this concise machine learning tutorial! We'll cover the essential concepts and build a simple ML model in just a few steps.\n",
    "\n",
    "## What We'll Cover:\n",
    "- Import libraries and load data\n",
    "- Explore the dataset\n",
    "- Prepare data for training\n",
    "- Train multiple ML models\n",
    "- Evaluate and compare results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9942f032",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f361d3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the famous Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data  # Features: sepal/petal length and width\n",
    "y = iris.target  # Target: flower species (0=setosa, 1=versicolor, 2=virginica)\n",
    "\n",
    "print(\"Dataset loaded successfully!\")\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"Feature names: {iris.feature_names}\")\n",
    "print(f\"Target names: {iris.target_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4325b3",
   "metadata": {},
   "source": [
    "## 2. Explore the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed16f74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for easier exploration\n",
    "df = pd.DataFrame(X, columns=iris.feature_names)\n",
    "df['species'] = iris.target_names[y]\n",
    "\n",
    "print(\"First 5 rows:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nDataset statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Simple visualization\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Scatter plot: Sepal length vs width\n",
    "plt.subplot(1, 3, 1)\n",
    "colors = ['red', 'blue', 'green']\n",
    "for i, species in enumerate(iris.target_names):\n",
    "    mask = y == i\n",
    "    plt.scatter(X[mask, 0], X[mask, 1], c=colors[i], label=species, alpha=0.7)\n",
    "plt.xlabel('Sepal Length')\n",
    "plt.ylabel('Sepal Width')\n",
    "plt.title('Sepal Dimensions')\n",
    "plt.legend()\n",
    "\n",
    "# Scatter plot: Petal length vs width\n",
    "plt.subplot(1, 3, 2)\n",
    "for i, species in enumerate(iris.target_names):\n",
    "    mask = y == i\n",
    "    plt.scatter(X[mask, 2], X[mask, 3], c=colors[i], label=species, alpha=0.7)\n",
    "plt.xlabel('Petal Length')\n",
    "plt.ylabel('Petal Width')\n",
    "plt.title('Petal Dimensions')\n",
    "plt.legend()\n",
    "\n",
    "# Species count\n",
    "plt.subplot(1, 3, 3)\n",
    "species_counts = df['species'].value_counts()\n",
    "plt.bar(species_counts.index, species_counts.values, color=['red', 'blue', 'green'], alpha=0.7)\n",
    "plt.title('Species Distribution')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nKey insights:\")\n",
    "print(f\"‚Ä¢ Dataset has {len(df)} samples of 3 iris species\")\n",
    "print(f\"‚Ä¢ Each species has exactly 50 samples (balanced dataset)\")\n",
    "print(f\"‚Ä¢ Petal dimensions seem to separate species better than sepal dimensions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d24f75",
   "metadata": {},
   "source": [
    "## 3. Prepare Data for Training\n",
    "\n",
    "We'll split our data into training and testing sets. The training set is used to teach the model, while the testing set evaluates how well it performs on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ba0861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Data split completed!\")\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing set: {X_test.shape[0]} samples\")\n",
    "print(f\"Features: {X_train.shape[1]}\")\n",
    "\n",
    "# Check class distribution in training set\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "print(f\"\\nTraining set class distribution:\")\n",
    "for i, count in enumerate(counts):\n",
    "    print(f\"  {iris.target_names[i]}: {count} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4031a2c",
   "metadata": {},
   "source": [
    "## 4. Train Machine Learning Models\n",
    "\n",
    "We'll train three different types of ML algorithms and compare their performance:\n",
    "- **Logistic Regression**: Linear model for classification\n",
    "- **Decision Tree**: Rule-based model that asks yes/no questions\n",
    "- **Random Forest**: Combines multiple decision trees for better accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df14778d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# Train models and store results\n",
    "results = {}\n",
    "\n",
    "print(\"Training models...\")\n",
    "for name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'predictions': y_pred,\n",
    "        'accuracy': accuracy\n",
    "    }\n",
    "    \n",
    "    print(f\"{name}: {accuracy:.3f} accuracy\")\n",
    "\n",
    "print(\"\\nTraining completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d26a3a",
   "metadata": {},
   "source": [
    "## 5. Evaluate and Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34093ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison DataFrame\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': list(results.keys()),\n",
    "    'Accuracy': [results[name]['accuracy'] for name in results.keys()]\n",
    "}).sort_values('Accuracy', ascending=False)\n",
    "\n",
    "print(\"Model Performance Comparison:\")\n",
    "print(comparison_df)\n",
    "\n",
    "# Visualize results\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Accuracy comparison\n",
    "plt.subplot(1, 2, 1)\n",
    "colors = ['gold', 'lightcoral', 'lightblue']\n",
    "bars = plt.bar(comparison_df['Model'], comparison_df['Accuracy'], color=colors)\n",
    "plt.title('Model Accuracy Comparison')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0.8, 1.0)\n",
    "\n",
    "# Add accuracy values on bars\n",
    "for bar, acc in zip(bars, comparison_df['Accuracy']):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005, \n",
    "             f'{acc:.3f}', ha='center', va='bottom')\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Feature importance (using Random Forest)\n",
    "plt.subplot(1, 2, 2)\n",
    "rf_model = results['Random Forest']['model']\n",
    "feature_importance = rf_model.feature_importances_\n",
    "plt.barh(iris.feature_names, feature_importance, color='lightgreen')\n",
    "plt.title('Feature Importance (Random Forest)')\n",
    "plt.xlabel('Importance')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Best model\n",
    "best_model = comparison_df.iloc[0]['Model']\n",
    "best_accuracy = comparison_df.iloc[0]['Accuracy']\n",
    "\n",
    "print(f\"\\nüèÜ Best Model: {best_model}\")\n",
    "print(f\"   Accuracy: {best_accuracy:.3f} ({best_accuracy*100:.1f}%)\")\n",
    "\n",
    "# Detailed classification report for best model\n",
    "print(f\"\\nDetailed Classification Report ({best_model}):\")\n",
    "best_predictions = results[best_model]['predictions']\n",
    "print(classification_report(y_test, best_predictions, target_names=iris.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018796be",
   "metadata": {},
   "source": [
    "## 6. Make Predictions on New Data\n",
    "\n",
    "Let's test our best model by predicting the species of some new iris flowers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61960a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some new flower measurements to predict\n",
    "new_flowers = np.array([\n",
    "    [5.1, 3.5, 1.4, 0.2],  # Small petals - likely Setosa\n",
    "    [6.2, 2.8, 4.8, 1.8],  # Medium size - likely Versicolor\n",
    "    [7.7, 3.8, 6.7, 2.2]   # Large petals - likely Virginica\n",
    "])\n",
    "\n",
    "flower_descriptions = [\n",
    "    \"Small flower (sepal: 5.1√ó3.5, petal: 1.4√ó0.2)\",\n",
    "    \"Medium flower (sepal: 6.2√ó2.8, petal: 4.8√ó1.8)\", \n",
    "    \"Large flower (sepal: 7.7√ó3.8, petal: 6.7√ó2.2)\"\n",
    "]\n",
    "\n",
    "# Use our best model to make predictions\n",
    "best_model_obj = results[best_model]['model']\n",
    "predictions = best_model_obj.predict(new_flowers)\n",
    "prediction_probabilities = best_model_obj.predict_proba(new_flowers)\n",
    "\n",
    "print(\"Predictions for new flowers:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i, (desc, pred, probs) in enumerate(zip(flower_descriptions, predictions, prediction_probabilities)):\n",
    "    predicted_species = iris.target_names[pred]\n",
    "    confidence = max(probs) * 100\n",
    "    \n",
    "    print(f\"\\n{i+1}. {desc}\")\n",
    "    print(f\"   Predicted species: {predicted_species}\")\n",
    "    print(f\"   Confidence: {confidence:.1f}%\")\n",
    "    \n",
    "    # Show probabilities for all species\n",
    "    print(\"   Probabilities:\")\n",
    "    for j, species in enumerate(iris.target_names):\n",
    "        print(f\"     {species}: {probs[j]*100:.1f}%\")\n",
    "\n",
    "# Visualize the predictions\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot existing data\n",
    "for i, species in enumerate(iris.target_names):\n",
    "    mask = y == i\n",
    "    plt.scatter(X[mask, 2], X[mask, 3], c=colors[i], label=f'{species} (training)', alpha=0.6, s=50)\n",
    "\n",
    "# Plot new predictions\n",
    "for i, (pred, flower) in enumerate(zip(predictions, new_flowers)):\n",
    "    plt.scatter(flower[2], flower[3], c=colors[pred], marker='X', s=200, \n",
    "               edgecolors='black', linewidth=2, label=f'New flower {i+1}')\n",
    "\n",
    "plt.xlabel('Petal Length')\n",
    "plt.ylabel('Petal Width')\n",
    "plt.title('New Flower Predictions vs Training Data')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüéØ Summary:\")\n",
    "print(f\"Successfully classified {len(new_flowers)} new flowers using {best_model}!\")\n",
    "print(f\"The model uses petal and sepal measurements to predict iris species.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288f99db",
   "metadata": {},
   "source": [
    "## üéâ Congratulations!\n",
    "\n",
    "You've completed a brief machine learning tutorial! Here's what you learned:\n",
    "\n",
    "### Key Concepts Covered:\n",
    "1. **Data Loading**: Using scikit-learn's built-in datasets\n",
    "2. **Data Exploration**: Understanding your data through statistics and visualization\n",
    "3. **Data Splitting**: Separating data into training and testing sets\n",
    "4. **Model Training**: Training multiple ML algorithms\n",
    "5. **Model Evaluation**: Comparing performance using accuracy metrics\n",
    "6. **Predictions**: Using trained models on new data\n",
    "\n",
    "### ML Algorithms Used:\n",
    "- **Logistic Regression**: Simple linear classifier\n",
    "- **Decision Tree**: Rule-based classifier\n",
    "- **Random Forest**: Ensemble method combining multiple trees\n",
    "\n",
    "### Next Steps:\n",
    "- Try different datasets (regression problems, larger datasets)\n",
    "- Explore data preprocessing (scaling, encoding categorical variables)\n",
    "- Learn about cross-validation and hyperparameter tuning\n",
    "- Study more advanced algorithms (SVM, Neural Networks, XGBoost)\n",
    "\n",
    "### Remember:\n",
    "- Machine learning is about finding patterns in data\n",
    "- Always split your data to properly evaluate models\n",
    "- Different algorithms work better for different problems\n",
    "- Feature engineering and data quality are crucial for success\n",
    "\n",
    "Happy machine learning! üöÄ"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
